{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cloudpickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "from coffea import hist, processor\n",
    "from coffea.util import load, save\n",
    "import coffea                        # Using coffea version 0.6.50\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from topcoffea.modules import samples\n",
    "from topcoffea.modules.fileReader import GetFiles, GetAllInfoFromFile\n",
    "\n",
    "outname = 'plotsTopEFT'              # Output pickle file name       \n",
    "nworkers = 10                        # For futures executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to configuration file; Note that the path in this configuration file is commented out\n",
    "cfgfile=('../cfg/samples.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary root file for testing\n",
    "path = \"root://cms-xrd-global.cern.ch//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options(path, sample, options = \"\"):\n",
    "    if not path.endswith('/'): path += '/'\n",
    "    if not sample.endswith(\".root\"): sample += '.root'\n",
    "  #doPUweight  = 'PUweight,' if IsVarInTree(path+sample, 'puWeight') else ''\n",
    "  #doJECunc    = 'JECunc,'   if IsVarInTree(path+sample, 'Jet_pt_jesTotalUp') else ''\n",
    "  #doIFSR      = 'doIFSR,'   if IsVarInTree(path+sample, 'nPSWeight') and GetValOfVarInTree(path+sample, 'nPSWeight') == 4 else ''\n",
    "  #useJetPtNom = 'JetPtNom,' if IsVarInTree(path+sample, 'Jet_pt_nom') else ''\n",
    "  #options += doPUweight + doJECunc + doIFSR + useJetPtNom + options\n",
    "    if options.endswith(','): options = options[:-1]\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewritten from topcoffea/topcoffea/modules/samples.py\n",
    "def get_dictionary(cfgfile, pretend=1,test=1,verbose=1,path='',sample='',xsec='xsec',year=-1,options='',treeName='Events'):\n",
    "    samplefiles = {}\n",
    "    fileopt = {}\n",
    "    xsecdic = {}\n",
    "    sampdic = {}\n",
    "    f = open(cfgfile)\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        l = l.replace(' ', '')\n",
    "        l = l.replace('\\n', '')\n",
    "        if l.startswith('#'): \n",
    "            continue\n",
    "        if '#' in l: l = l.split('#')[0]\n",
    "        if l == '': continue\n",
    "        if l.endswith(':'): l = l[:-1]\n",
    "        if not ':' in l:\n",
    "            if l in ['path', 'verbose', 'pretend', 'test', 'options', 'xsec', 'year', 'treeName']: continue\n",
    "            else: samplefiles[l]=l\n",
    "        else:\n",
    "            lst = l.split(':')\n",
    "            key = lst[0]\n",
    "            val = lst[1] if lst[1] != '' else lst[0]\n",
    "            if   key == 'pretend'   : pretend   = 1\n",
    "            elif key == 'verbose'   : verbose   = int(val) if val.isdigit() else 1\n",
    "            elif key == 'test'      : dotest    = 1\n",
    "            elif key == 'path'      :\n",
    "                path = val\n",
    "                if len(lst) > 2: \n",
    "                    for v in lst[2:]: path += ':'+v\n",
    "            elif key == 'options'   : options   = val\n",
    "            elif key == 'xsec'      : xsec      = val\n",
    "            elif key == 'year'      : year      = int(val)\n",
    "            elif key == 'treeName'  : treeName  = val\n",
    "            else:\n",
    "                fileopt[key] = options\n",
    "                if len(lst) >= 3: fileopt[key] += lst[2]\n",
    "                samplefiles[key] = val\n",
    "    \n",
    "    \n",
    "    #xsecdic = loadxsecdic(xsec, verbose)\n",
    "    \n",
    "    for sname in samplefiles.keys():\n",
    "        sampdic[sname] = {}\n",
    "        #sampdic[sname]['files']      = GetFiles(path, samplefiles[sname])\n",
    "        sampdic[sname]['files']      = [path]     #temporaraily hard-coding the paths with the testing file\n",
    "        extraOption = get_options(path, sampdic[sname]['files'][0].split('/')[-1])\n",
    "        sampdic[sname]['options']    = fileopt[sname] + ', ' + extraOption\n",
    "        sampdic[sname]['xsec']       = xsecdic[sname] if sname in xsecdic.keys() else 1\n",
    "        sampdic[sname]['year']       = year\n",
    "        sampdic[sname]['treeName']   = treeName\n",
    "        nEvents, nGenEvents, nSumOfWeights, isData = GetAllInfoFromFile(sampdic[sname]['files'], sampdic[sname]['treeName'])\n",
    "        sampdic[sname]['nEvents']       = nEvents\n",
    "        sampdic[sname]['nGenEvents']    = nGenEvents\n",
    "        sampdic[sname]['nSumOfWeights'] = nSumOfWeights\n",
    "        sampdic[sname]['isData']        = isData        \n",
    "    return(sampdic)\n",
    "\n",
    "#   Re-assign arguments...\n",
    "#   aarg = sys.argv\n",
    "#   if '--pretend' in aarg or '-p' in aarg : pretend     = args.pretend\n",
    "#   if '--test'    in aarg or '-t' in aarg : dotest      = args.test\n",
    "#   if args.path       != ''       : path        = args.path\n",
    "#   if args.options    != ''       : options     = args.options\n",
    "#   if args.xsec       != 'xsec'   : xsec        = args.xsec\n",
    "#   if args.year       != -1       : year        = args.year\n",
    "#   if args.treeName   != 'Events' : treeName    = args.treeName\n",
    "#   if args.verbose    != 0        : verbose     = int(args.verbose)\n",
    "#   xsecdic = loadxsecdic(xsec, verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesdict = get_dictionary(cfgfile,path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = {}; xsec = {}; sow = {}; isData = {}\n",
    "for k in samplesdict.keys():\n",
    "    flist[k] = samplesdict[k]['files']\n",
    "    xsec[k]  = samplesdict[k]['xsec']\n",
    "    sow[k]   = samplesdict[k]['nSumOfWeights']\n",
    "    isData[k]= samplesdict[k]['isData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewritten from topcoffea/analysis/topEFT/\n",
    "import cloudpickle\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "import awkward\n",
    "np.seterr(divide='ignore', invalid='ignore', over='ignore')\n",
    "from coffea.arrays import Initialize\n",
    "#from optparse import OptionParser\n",
    "\n",
    "from topcoffea.modules.objects import *\n",
    "from topcoffea.modules.corrections import *\n",
    "from topcoffea.modules.selection import *\n",
    "from topcoffea.modules.HistEFT import HistEFT\n",
    "\n",
    "# In the future these names will be read from the nanoAOD files\n",
    "WCNames = ['ctW', 'ctp', 'cpQM', 'ctli', 'cQei', 'ctZ', 'cQlMi', 'cQl3i', 'ctG', 'ctlTi', 'cbW', 'cpQ3', 'ctei', 'cpt', 'ctlSi', 'cptb']\n",
    "\n",
    "\n",
    "class AnalysisProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, samples):\n",
    "        self._samples = samples\n",
    "\n",
    "        # Create the histograms\n",
    "        # In general, histograms depend on 'sample', 'channel' (final state) and 'cut' (level of selection)\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "        'SumOfEFTweights'  : HistEFT(\"SumOfWeights\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Bin(\"SumOfEFTweights\", \"sow\", 1, 0, 2)),\n",
    "        'dummy'   : hist.Hist(\"Dummy\" , hist.Cat(\"sample\", \"sample\"), hist.Bin(\"dummy\", \"Number of events\", 1, 0, 1)),\n",
    "        'counts'  : hist.Hist(\"Events\", hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"counts\", \"Counts\", 1, 0, 2)),\n",
    "        'invmass' : hist.Hist(\"Events\", hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\",\"cut\"), hist.Bin(\"invmass\", \"$m_{\\ell\\ell}$ (GeV) \", 20, 0, 200)),\n",
    "        'njets'   : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"njets\",  \"Jet multiplicitu \", 10, 0, 10)),\n",
    "        'nbtags'  : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"nbtags\", \"btag multiplicitu \", 5, 0, 5)),\n",
    "        'met'     : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"met\",    \"MET (GeV)\", 40, 0, 400)),\n",
    "        'm3l'     : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"m3l\",    \"$m_{3\\ell}$ (GeV) \", 20, 0, 200)),\n",
    "        'wleppt'  : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"wleppt\", \"$p_{T}^{lepW}$ (GeV) \", 20, 0, 200)),\n",
    "        'e0pt'    : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"e0pt\",   \"Leading elec $p_{T}$ (GeV)\", 30, 0, 300)),\n",
    "        'm0pt'    : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"m0pt\",   \"Leading muon $p_{T}$ (GeV)\", 30, 0, 300)),\n",
    "        'j0pt'    : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"j0pt\",   \"Leading jet  $p_{T}$ (GeV)\", 20, 0, 400)),\n",
    "        'e0eta'   : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"e0eta\",  \"Leading elec $\\eta$\", 20, -2.5, 2.5)),\n",
    "        'm0eta'   : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"m0eta\",  \"Leading muon $\\eta$\", 20, -2.5, 2.5)),\n",
    "        'j0eta'   : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"j0eta\",  \"Leading jet  $\\eta$\", 20, -2.5, 2.5)),\n",
    "        'ht'      : HistEFT(\"Events\", WCNames, hist.Cat(\"sample\", \"sample\"), hist.Cat(\"channel\", \"channel\"), hist.Cat(\"cut\", \"cut\"), hist.Bin(\"ht\",     \"H$_{T}$ (GeV)\", 40, 0, 800)),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._columns\n",
    "\n",
    "    # Main function: run on a given dataset\n",
    "    def process(self, events):\n",
    "        # Dataset parameters\n",
    "        dataset = events.metadata['dataset']\n",
    "        year   = self._samples[dataset]['year']\n",
    "        xsec   = self._samples[dataset]['xsec']\n",
    "        sow    = self._samples[dataset]['nSumOfWeights' ]\n",
    "        isData = self._samples[dataset]['isData']\n",
    "        datasets = ['SingleMuon', 'SingleElectron', 'EGamma', 'MuonEG', 'DoubleMuon', 'DoubleElectron']\n",
    "        for d in datasets: \n",
    "          if d in dataset: dataset = dataset.split('_')[0] \n",
    "\n",
    "        # Initialize objects\n",
    "        met = events.MET\n",
    "        e   = events.Electron\n",
    "        mu  = events.Muon\n",
    "        j   = events.Jet\n",
    " \n",
    "\n",
    "        # Electron selection\n",
    "        #e['isGood'] = e.pt.zeros_like()\n",
    "        e['isGood'] = isElecMVA(e.pt, e.eta, e.dxy, e.dz, e.miniPFRelIso_all, e.sip3d, e.mvaTTH, e.mvaFall17V2Iso, e.lostHits, e.convVeto, e.tightCharge, minpt=10)\n",
    "        leading_e = e[e.pt.argmax()]\n",
    "        leading_e = leading_e[leading_e.isGood.astype(np.bool)]\n",
    "\n",
    "        # Muon selection\n",
    "        mu['isGood'] = isMuonMVA(mu.pt, mu.eta, mu.dxy, mu.dz, mu.miniPFRelIso_all, mu.sip3d, mu.mvaTTH, mu.mediumPromptId, mu.tightCharge, minpt=10)\n",
    "        leading_mu = mu[mu.pt.argmax()]\n",
    "        leading_mu = leading_mu[leading_mu.isGood.astype(np.bool)]\n",
    "        \n",
    "        e  =  e[e .isGood.astype(np.bool)]\n",
    "        mu = mu[mu.isGood.astype(np.bool)]\n",
    "        nElec = e .counts\n",
    "        nMuon = mu.counts\n",
    "\n",
    "        twoLeps   = (nElec+nMuon) == 2\n",
    "        threeLeps = (nElec+nMuon) == 3\n",
    "        twoElec   = (nElec == 2)\n",
    "        twoMuon   = (nMuon == 2)\n",
    "        e0 = e[e.pt.argmax()]\n",
    "        m0 = mu[mu.pt.argmax()]\n",
    "\n",
    "        # Jet selection\n",
    "        j['isgood']  = isGoodJet(j.pt, j.eta, j.jetId)\n",
    "        j['isclean'] = isClean(j, e, mu)\n",
    "        goodJets = j[(j.isclean)&(j.isgood)]\n",
    "        njets = goodJets.counts\n",
    "        ht = goodJets.pt.sum()\n",
    "        j0 = goodJets[goodJets.pt.argmax()]\n",
    "        nbtags = goodJets[goodJets.btagDeepFlavB > 0.2770].counts\n",
    "\n",
    "\n",
    "        ##################################################################\n",
    "        ### 2 same-sign leptons\n",
    "        ##################################################################\n",
    "\n",
    "        # emu\n",
    "        singe = e [(nElec==1)&(nMuon==1)&(e .pt>-1)]\n",
    "        singm = mu[(nElec==1)&(nMuon==1)&(mu.pt>-1)]\n",
    "        em = singe.cross(singm)\n",
    "        emSSmask = (em.i0.charge*em.i1.charge>0)\n",
    "        emSS = em[emSSmask]\n",
    "        nemSS = len(emSS.flatten())\n",
    "\n",
    "        # ee and mumu\n",
    "        # pt>-1 to preserve jagged dimensions\n",
    "        ee = e [(nElec==2)&(nMuon==0)&(e.pt>-1)]\n",
    "        mm = mu[(nElec==0)&(nMuon==2)&(mu.pt>-1)]\n",
    "\n",
    "        eepairs = ee.distincts()\n",
    "        eeSSmask = (eepairs.i0.charge*eepairs.i1.charge>0)\n",
    "        eeonZmask  = (np.abs((eepairs.i0+eepairs.i1).mass-91)<15)\n",
    "        eeoffZmask = (eeonZmask==0)\n",
    "\n",
    "        mmpairs = mm.distincts()\n",
    "        mmSSmask = (mmpairs.i0.charge*mmpairs.i1.charge>0)\n",
    "        mmonZmask  = (np.abs((mmpairs.i0+mmpairs.i1).mass-91)<15)\n",
    "        mmoffZmask = (mmonZmask==0)\n",
    "\n",
    "        eeSSonZ  = eepairs[eeSSmask &  eeonZmask]\n",
    "        eeSSoffZ = eepairs[eeSSmask & eeoffZmask]\n",
    "        mmSSonZ  = mmpairs[mmSSmask &  mmonZmask]\n",
    "        mmSSoffZ = mmpairs[mmSSmask & mmoffZmask]\n",
    "        neeSS = len(eeSSonZ.flatten()) + len(eeSSoffZ.flatten())\n",
    "        nmmSS = len(mmSSonZ.flatten()) + len(mmSSoffZ.flatten())\n",
    "\n",
    "        #print('Same-sign events [ee, emu, mumu] = [%i, %i, %i]'%(neeSS, nemSS, nmmSS))\n",
    "\n",
    "        # Cuts\n",
    "        eeSSmask   = (eeSSmask[eeSSmask].counts>0)\n",
    "        mmSSmask   = (mmSSmask[mmSSmask].counts>0)\n",
    "        eeonZmask  = (eeonZmask[eeonZmask].counts>0)\n",
    "        eeoffZmask = (eeoffZmask[eeoffZmask].counts>0)\n",
    "        mmonZmask  = (mmonZmask[mmonZmask].counts>0)\n",
    "        mmoffZmask = (mmoffZmask[mmoffZmask].counts>0)\n",
    "        emSSmask    = (emSSmask[emSSmask].counts>0)\n",
    "\n",
    "        # njets\n",
    "\n",
    "        ##################################################################\n",
    "        ### 3 leptons\n",
    "        ##################################################################\n",
    "\n",
    "        # eem\n",
    "        muon_eem = mu[(nElec==2)&(nMuon==1)&(mu.pt>-1)]\n",
    "        elec_eem =  e[(nElec==2)&(nMuon==1)&( e.pt>-1)]\n",
    "        ee_eem   = elec_eem.distincts()\n",
    "        ee_eemZmask     = (ee_eem.i0.charge*ee_eem.i1.charge<1)&(np.abs((ee_eem.i0+ee_eem.i1).mass-91)<15)\n",
    "        ee_eemOffZmask  = (ee_eem.i0.charge*ee_eem.i1.charge<1)&(np.abs((ee_eem.i0+ee_eem.i1).mass-91)>15)\n",
    "        ee_eemZmask     = (ee_eemZmask[ee_eemZmask].counts>0)\n",
    "        ee_eemOffZmask  = (ee_eemOffZmask[ee_eemOffZmask].counts>0)\n",
    "\n",
    "        eepair_eem     = (ee_eem.i0+ee_eem.i1)\n",
    "        trilep_eem     = eepair_eem.cross(muon_eem)\n",
    "        trilep_eem     = (trilep_eem.i0+trilep_eem.i1) \n",
    "\n",
    "        # mme\n",
    "        muon_mme = mu[(nElec==1)&(nMuon==2)&(mu.pt>-1)]\n",
    "        elec_mme =  e[(nElec==1)&(nMuon==2)&( e.pt>-1)]\n",
    "        mm_mme   = muon_mme.distincts()\n",
    "        mm_mmeZmask     = (mm_mme.i0.charge*mm_mme.i1.charge<1)&(np.abs((mm_mme.i0+mm_mme.i1).mass-91)<15)\n",
    "        mm_mmeOffZmask  = (mm_mme.i0.charge*mm_mme.i1.charge<1)&(np.abs((mm_mme.i0+mm_mme.i1).mass-91)>15)\n",
    "        mm_mmeZmask     = (mm_mmeZmask[mm_mmeZmask].counts>0)\n",
    "        mm_mmeOffZmask  = (mm_mmeOffZmask[mm_mmeOffZmask].counts>0)\n",
    "\n",
    "        mmpair_mme     = (mm_mme.i0+mm_mme.i1)\n",
    "        trilep_mme     = mmpair_mme.cross(elec_mme)\n",
    "        trilep_mme     = (trilep_mme.i0+trilep_mme.i1)\n",
    "        mZ_mme  = mmpair_mme.mass\n",
    "        mZ_eem  = eepair_eem.mass\n",
    "        m3l_eem = trilep_eem.mass\n",
    "        m3l_mme = trilep_mme.mass\n",
    "\n",
    "\n",
    "        ### eee and mmm\n",
    "        eee =   e[(nElec==3)&(nMuon==0)&( e.pt>-1)] \n",
    "        mmm =  mu[(nElec==0)&(nMuon==3)&(mu.pt>-1)] \n",
    "        # Create pairs\n",
    "        ee_pairs = eee.argchoose(2)\n",
    "        mm_pairs = mmm.argchoose(2)\n",
    "\n",
    "        # Select pairs that are SFOS.\n",
    "        eeSFOS_pairs = ee_pairs[(np.abs(eee[ee_pairs.i0].pdgId) == np.abs(eee[ee_pairs.i1].pdgId)) & (eee[ee_pairs.i0].charge != eee[ee_pairs.i1].charge)]\n",
    "        mmSFOS_pairs = mm_pairs[(np.abs(mmm[mm_pairs.i0].pdgId) == np.abs(mmm[mm_pairs.i1].pdgId)) & (mmm[mm_pairs.i0].charge != mmm[mm_pairs.i1].charge)]\n",
    "        # Find the pair with mass closest to Z.\n",
    "        eeOSSFmask = eeSFOS_pairs[np.abs((eee[eeSFOS_pairs.i0] + eee[eeSFOS_pairs.i1]).mass - 91.2).argmin()]\n",
    "        onZmask_ee = np.abs((eee[eeOSSFmask.i0] + eee[eeOSSFmask.i1]).mass - 91.2) < 15\n",
    "        mmOSSFmask = mmSFOS_pairs[np.abs((mmm[mmSFOS_pairs.i0] + mmm[mmSFOS_pairs.i1]).mass - 91.2).argmin()]\n",
    "        onZmask_mm = np.abs((mmm[mmOSSFmask.i0] + mmm[mmOSSFmask.i1]).mass - 91.2) < 15\n",
    "        offZmask_ee = np.abs((eee[eeOSSFmask.i0] + eee[eeOSSFmask.i1]).mass - 91.2) > 15\n",
    "        offZmask_mm = np.abs((mmm[mmOSSFmask.i0] + mmm[mmOSSFmask.i1]).mass - 91.2) > 15\n",
    "\n",
    "        # Create masks\n",
    "        eeeOnZmask  = onZmask_ee[onZmask_ee].counts>0\n",
    "        eeeOffZmask = offZmask_ee[offZmask_ee].counts>0\n",
    "        mmmOnZmask  = onZmask_mm[onZmask_mm].counts>0\n",
    "        mmmOffZmask = offZmask_mm[offZmask_mm].counts>0\n",
    "    \n",
    "        # Leptons from Z\n",
    "        eZ0= eee[eeOSSFmask.i0]\n",
    "        eZ1= eee[eeOSSFmask.i1]\n",
    "        mZ0= mmm[mmOSSFmask.i0]\n",
    "        mZ1= mmm[mmOSSFmask.i1]\n",
    "\n",
    "        # Leptons from W\n",
    "        eW = eee[~eeOSSFmask.i0 | ~eeOSSFmask.i1]\n",
    "        mW = mmm[~mmOSSFmask.i0 | ~mmOSSFmask.i1]\n",
    "\n",
    "        eZ = eee[eeOSSFmask.i0] + eee[eeOSSFmask.i1]\n",
    "        triElec = eZ + eW\n",
    "        mZ = mmm[mmOSSFmask.i0] + mmm[mmOSSFmask.i1]\n",
    "        triMuon = mZ + mW\n",
    "\n",
    "        mZ_eee  = eZ.mass\n",
    "        m3l_eee = triElec.mass\n",
    "        mZ_mmm  = mZ.mass\n",
    "        m3l_mmm = triMuon.mass\n",
    "    \n",
    "        # Triggers\n",
    "        #passTrigger = lambda events, n, m, o : np.ones_like(events['MET_pt'], dtype=np.bool) # XXX\n",
    "        trig_eeSS = passTrigger(events,'ee',isData,dataset)\n",
    "        trig_mmSS = passTrigger(events,'mm',isData,dataset)\n",
    "        trig_emSS = passTrigger(events,'em',isData,dataset)\n",
    "        trig_eee  = passTrigger(events,'eee',isData,dataset)\n",
    "        trig_mmm  = passTrigger(events,'mmm',isData,dataset)\n",
    "        trig_eem  = passTrigger(events,'eem',isData,dataset)\n",
    "        trig_mme  = passTrigger(events,'mme',isData,dataset)\n",
    "\n",
    "\n",
    "        # MET filters\n",
    "\n",
    "        # Weights\n",
    "        genw = np.ones_like(events['MET_pt']) if isData else events['genWeight']\n",
    "        weights = processor.Weights(events.size)\n",
    "        weights.add('norm',genw if isData else (xsec/sow)*genw)\n",
    "        eftweights = events['EFTfitCoefficients'] if hasattr(events, \"EFTfitCoefficients\") else []\n",
    "\n",
    "        # Selections and cuts\n",
    "        selections = processor.PackedSelection()\n",
    "        channels2LSS = ['eeSSonZ', 'eeSSoffZ', 'mmSSonZ', 'mmSSoffZ', 'emSS']\n",
    "        selections.add('eeSSonZ',  (eeonZmask)&(eeSSmask)&(trig_eeSS))\n",
    "        selections.add('eeSSoffZ', (eeoffZmask)&(eeSSmask)&(trig_eeSS))\n",
    "        selections.add('mmSSonZ',  (mmonZmask)&(mmSSmask)&(trig_mmSS))\n",
    "        selections.add('mmSSoffZ', (mmoffZmask)&(mmSSmask)&(trig_mmSS))\n",
    "        selections.add('emSS',     (emSSmask)&(trig_emSS))\n",
    "\n",
    "        channels3L = ['eemSSonZ', 'eemSSoffZ', 'mmeSSonZ', 'mmeSSoffZ']\n",
    "        selections.add('eemSSonZ',   (ee_eemZmask)&(trig_eem))\n",
    "        selections.add('eemSSoffZ',  (ee_eemOffZmask)&(trig_eem))\n",
    "        selections.add('mmeSSonZ',   (mm_mmeZmask)&(trig_mme))\n",
    "        selections.add('mmeSSoffZ',  (mm_mmeOffZmask)&(trig_mme))\n",
    "\n",
    "        channels3L += ['eeeSSonZ', 'eeeSSoffZ', 'mmmSSonZ', 'mmmSSoffZ']\n",
    "        selections.add('eeeSSonZ',   (eeeOnZmask)&(trig_eee))\n",
    "        selections.add('eeeSSoffZ',  (eeeOffZmask)&(trig_eee))\n",
    "        selections.add('mmmSSonZ',   (mmmOnZmask)&(trig_mmm))\n",
    "        selections.add('mmmSSoffZ',  (mmmOffZmask)&(trig_mmm))\n",
    "\n",
    "        levels = ['base', '2jets', '4jets', '4j1b', '4j2b']\n",
    "        selections.add('base', (nElec+nMuon>=2))\n",
    "        selections.add('2jets',(njets>=2))\n",
    "        selections.add('4jets',(njets>=4))\n",
    "        selections.add('4j1b',(njets>=4)&(nbtags>=1))\n",
    "        selections.add('4j2b',(njets>=4)&(nbtags>=2))\n",
    "\n",
    "        # Variables\n",
    "        invMass_eeSSonZ  = ( eeSSonZ.i0+ eeSSonZ.i1).mass\n",
    "        invMass_eeSSoffZ = (eeSSoffZ.i0+eeSSoffZ.i1).mass\n",
    "        invMass_mmSSonZ  = ( mmSSonZ.i0+ mmSSonZ.i1).mass\n",
    "        invMass_mmSSoffZ = (mmSSoffZ.i0+mmSSoffZ.i1).mass\n",
    "        invMass_emSS     = (emSS.i0+emSS.i1).mass\n",
    "\n",
    "        varnames = {}\n",
    "        varnames['met'] = met.pt\n",
    "        varnames['ht'] = ht\n",
    "        varnames['njets'] = njets\n",
    "        varnames['nbtags'] = nbtags\n",
    "        varnames['invmass'] = {\n",
    "          'eeSSonZ'   : invMass_eeSSonZ,\n",
    "          'eeSSoffZ'  : invMass_eeSSoffZ,\n",
    "          'mmSSonZ'   : invMass_mmSSonZ,\n",
    "          'mmSSoffZ'  : invMass_mmSSoffZ,\n",
    "          'emSS'      : invMass_emSS,\n",
    "          'eemSSonZ'  : mZ_eem,\n",
    "          'eemSSoffZ' : mZ_eem,\n",
    "          'mmeSSonZ'  : mZ_mme,\n",
    "          'mmeSSoffZ' : mZ_mme,\n",
    "          'eeeSSonZ'  : mZ_eee,\n",
    "          'eeeSSoffZ' : mZ_eee,\n",
    "          'mmmSSonZ'  : mZ_mmm,\n",
    "          'mmmSSoffZ' : mZ_mmm,\n",
    "        }\n",
    "        varnames['m3l'] = {\n",
    "          'eemSSonZ'  : m3l_eem,\n",
    "          'eemSSoffZ' : m3l_eem,\n",
    "          'mmeSSonZ'  : m3l_mme,\n",
    "          'mmeSSoffZ' : m3l_mme,\n",
    "          'eeeSSonZ'  : m3l_eee,\n",
    "          'eeeSSoffZ' : m3l_eee,\n",
    "          'mmmSSonZ'  : m3l_mmm,\n",
    "          'mmmSSoffZ' : m3l_mmm,\n",
    "        }\n",
    "        varnames['e0pt' ] = e0.pt\n",
    "        varnames['e0eta'] = e0.eta\n",
    "        varnames['m0pt' ] = m0.pt\n",
    "        varnames['m0eta'] = m0.eta\n",
    "        varnames['j0pt' ] = j0.pt\n",
    "        varnames['j0eta'] = j0.eta\n",
    "        varnames['counts'] = np.ones_like(events.MET.pt, dtype=np.int) \n",
    "\n",
    "        # fill Histos\n",
    "        hout = self.accumulator.identity()\n",
    "        allweights = weights.weight().flatten()\n",
    "        #hout['dummy'].fill(sample=dataset, dummy=varnames['counts'], weight=np.ones_like(events.MET.pt, dtype=np.int))\n",
    "        hout['SumOfEFTweights'].fill(eftweights, sample=dataset, SumOfEFTweights=varnames['counts'], weight=allweights)\n",
    "\n",
    "        for var, v in varnames.items():\n",
    "            for ch in channels2LSS+channels3L:\n",
    "                for lev in levels:\n",
    "                    weight = weights.weight()\n",
    "                    cuts = [ch] + [lev]\n",
    "                    cut = selections.all(*cuts)\n",
    "                    weights_flat = weight[cut].flatten()\n",
    "                    weights_ones = np.ones_like(weights_flat, dtype=np.int)\n",
    "                    eftweightsvalues = eftweights[cut] if len(eftweights) > 0 else []\n",
    "                    if var == 'invmass':\n",
    "                        if   ch in ['eeeSSoffZ', 'mmmSSoffZ']: continue\n",
    "                        elif ch in ['eeeSSonZ' , 'mmmSSonZ' ]: continue #values = v[ch]\n",
    "                        else                                 : values = v[ch][cut].flatten()\n",
    "                        hout['invmass'].fill(sample=dataset, channel=ch, cut=lev, invmass=values, weight=weights_flat)\n",
    "                    elif var == 'm3l': \n",
    "                        if ch in ['eeSSonZ','eeSSoffZ', 'mmSSonZ', 'mmSSoffZ','emSS', 'eeeSSoffZ', 'mmmSSoffZ', 'eeeSSonZ' , 'mmmSSonZ']: continue\n",
    "                        values = v[ch][cut].flatten()\n",
    "                        hout['m3l'].fill(eftweightsvalues, sample=dataset, channel=ch, cut=lev, m3l=values, weight=weights_flat)\n",
    "                    else:\n",
    "                        values = v[cut].flatten()\n",
    "                        if   var == 'ht'    : hout[var].fill(eftweightsvalues, ht=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'met'   : hout[var].fill(eftweightsvalues, met=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'njets' : hout[var].fill(eftweightsvalues, njets=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'nbtags': hout[var].fill(eftweightsvalues, nbtags=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'counts': hout[var].fill(counts=values, sample=dataset, channel=ch, cut=lev, weight=weights_ones)\n",
    "                        elif var == 'j0eta' : \n",
    "                            if lev == 'base': continue\n",
    "                            hout[var].fill(eftweightsvalues, j0eta=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'e0pt'  : \n",
    "                            if ch in ['mmSSonZ', 'mmSSoffZ', 'mmmSSoffZ', 'mmmSSonZ']: continue\n",
    "                            hout[var].fill(eftweightsvalues, e0pt=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'm0pt'  : \n",
    "                            if ch in ['eeSSonZ', 'eeSSoffZ', 'eeeSSoffZ', 'eeeSSonZ']: continue\n",
    "                            hout[var].fill(eftweightsvalues, m0pt=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'e0eta' : \n",
    "                            if ch in ['mmSSonZ', 'mmSSoffZ', 'mmmSSoffZ', 'mmmSSonZ']: continue\n",
    "                            hout[var].fill(eftweightsvalues, e0eta=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'm0eta':\n",
    "                            if ch in ['eeSSonZ', 'eeSSoffZ', 'eeeSSoffZ', 'eeeSSonZ']: continue\n",
    "                            hout[var].fill(eftweightsvalues, m0eta=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "                        elif var == 'j0pt'  : \n",
    "                            if lev == 'base': continue\n",
    "                            hout[var].fill(eftweightsvalues, j0pt=values, sample=dataset, channel=ch, cut=lev, weight=weights_flat)\n",
    "\n",
    "        return hout\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_instance = AnalysisProcessor(samplesdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DYJetsToLL_MLL50': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'DYJetsToLL_M_10to50': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'ZZTo2L2Nu': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'ZZTo4L': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'WZTo3LNU': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'WWTo2L2Nu': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'tW_noFullHad': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'tbarW_noFullHad': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'TT': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root'],\n",
       " 'TTsemilep': ['root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with just with one item from filelist, since I don't have Xuan's files,  all paths in the filelist are copies of each other\n",
    "flist = {'DYJetsToLL_MLL50': [\"root://xcache//store/user/jrgonzal/nanoAODttH/8F38C0F2-E7A7-C846-BBF5-0C040E6BA839.root\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f7bd0d18574f5db73816c11c263d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Preprocessing'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8146a7ae96f64bb3b9711c16e296c9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Processing'), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/coffea/util.py:98: Awkward0Warning: In coffea version 0.7 (target date: January 2021), this will be an error.\n",
      "(Set awkward1.deprecations_as_errors = True to get a stack trace now.)\n",
      "TypeError: <class 'coffea.nanoaod.nanoevents.NanoEvents'> relies exclusively on awkward 0.x and will be removed in upcoming versions of coffea!\n",
      "  warnings.warn(message, Awkward0Warning)\n",
      "/opt/conda/lib/python3.8/site-packages/coffea/util.py:98: Awkward0Warning: In coffea version 0.7 (target date: January 2021), this will be an error.\n",
      "(Set awkward1.deprecations_as_errors = True to get a stack trace now.)\n",
      "TypeError: <class 'coffea.nanoaod.nanoevents.NanoCollection'> relies exclusively on awkward 0.x and will be removed in upcoming versions of coffea!\n",
      "  warnings.warn(message, Awkward0Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "output = processor.run_uproot_job(flist, \n",
    "                                  treename='Events', \n",
    "                                  processor_instance=processor_instance, \n",
    "                                  executor=processor.futures_executor, \n",
    "                                  executor_args={'nano':True}, \n",
    "                                  chunksize=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 161460 bins, nonzero bins: 74.3 %\n",
      "Processing time: 3911.25 s with 10 workers (39112.51 s cpu overall)\n",
      "Saving output in histos/plotsTopEFT.pkl.gz...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dt = time.time() - tstart\n",
    "\n",
    "nbins = sum(sum(arr.size for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "nfilled = sum(sum(np.sum(arr > 0) for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "print(\"Filled %.0f bins, nonzero bins: %1.1f %%\" % (nbins, 100*nfilled/nbins,))\n",
    "print(\"Processing time: %1.2f s with %i workers (%.2f s cpu overall)\" % (dt, nworkers, dt*nworkers, ))\n",
    "\n",
    "os.system(\"mkdir -p histos/\")\n",
    "print('Saving output in %s...'%(\"histos/\" + outname + \".pkl.gz\"))\n",
    "with gzip.open(\"histos/\" + outname + \".pkl.gz\", \"wb\") as fout:\n",
    "    cloudpickle.dump(output, fout)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SumOfEFTweights': <HistEFT (sample,SumOfEFTweights) instance at 0x7ffadb6b1ca0>,\n",
       " 'dummy': <Hist (sample,dummy) instance at 0x7ffadbe1de80>,\n",
       " 'counts': <Hist (sample,channel,cut,counts) instance at 0x7ffadbe36ca0>,\n",
       " 'invmass': <Hist (sample,channel,cut,invmass) instance at 0x7ffadbfcc1c0>,\n",
       " 'njets': <HistEFT (sample,channel,cut,njets) instance at 0x7ffadbfcc070>,\n",
       " 'nbtags': <HistEFT (sample,channel,cut,nbtags) instance at 0x7ffadbfcc4f0>,\n",
       " 'met': <HistEFT (sample,channel,cut,met) instance at 0x7ffadbfcc790>,\n",
       " 'm3l': <HistEFT (sample,channel,cut,m3l) instance at 0x7ffadbe36a30>,\n",
       " 'wleppt': <HistEFT (sample,channel,cut,wleppt) instance at 0x7ffadc133e80>,\n",
       " 'e0pt': <HistEFT (sample,channel,cut,e0pt) instance at 0x7ffadbe369a0>,\n",
       " 'm0pt': <HistEFT (sample,channel,cut,m0pt) instance at 0x7ffadbe361c0>,\n",
       " 'j0pt': <HistEFT (sample,channel,cut,j0pt) instance at 0x7ffadc15e130>,\n",
       " 'e0eta': <HistEFT (sample,channel,cut,e0eta) instance at 0x7ffadbe36400>,\n",
       " 'm0eta': <HistEFT (sample,channel,cut,m0eta) instance at 0x7ffadc143160>,\n",
       " 'j0eta': <HistEFT (sample,channel,cut,j0eta) instance at 0x7ffadecd0d30>,\n",
       " 'ht': <HistEFT (sample,channel,cut,ht) instance at 0x7ffadecd0be0>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
