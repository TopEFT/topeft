{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f467b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Obtaining file:///home/cms-jovyan/topcoffea\n",
      "Installing collected packages: topcoffea\n",
      "  Attempting uninstall: topcoffea\n",
      "    Found existing installation: topcoffea 0.0.0\n",
      "    Uninstalling topcoffea-0.0.0:\n",
      "      Successfully uninstalled topcoffea-0.0.0\n",
      "  Running setup.py develop for topcoffea\n",
      "Successfully installed topcoffea\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/TopEFT/topcoffea.git#egg=topcoffea\n",
    "! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781aeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lz4.frame as lz4f\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import cloudpickle\n",
    "import gzip\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "from coffea import hist, processor\n",
    "from coffea.util import load, save\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "\n",
    "from topcoffea.modules import samples\n",
    "from topcoffea.modules import fileReader\n",
    "\n",
    "#FIXME: analysis is not installed anywhere (should be installed as well)\n",
    "import topcoffea.analysis.topEFT.topeft\n",
    "\n",
    "import importlib.resources\n",
    "\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    import sys\n",
    "    sys.argv = ['']\n",
    "    \n",
    "from dask.distributed import Client, Worker, WorkerPlugin\n",
    "import os\n",
    "from typing import List\n",
    "class DependencyInstaller(WorkerPlugin):\n",
    "    def __init__(self, dependencies: List[str]):\n",
    "        self._depencendies = \" \".join(f\"'{dep}'\" for dep in dependencies)\n",
    "    def setup(self, worker: Worker):\n",
    "        os.system(f\"pip install {self._depencendies}\")\n",
    "dependency_installer = DependencyInstaller([\n",
    "    \"git+https://github.com/TopEFT/topcoffea.git#egg=topcoffea\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0286ca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsonFile was selected for UNL /home/cms-jovyan/topcoffea/topcoffea/json/TTZToLLNuNu_M10.json\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='You can customize your run')\n",
    "parser.add_argument('jsonFiles'           , nargs='?', help = 'Json file(s) containing files and metadata')\n",
    "parser.add_argument('--prefix', '-r'     , nargs='?', help = 'Prefix or redirector to look for the files')\n",
    "parser.add_argument('--test','-t'       , action='store_true'  , help = 'To perform a test, run over a few events in a couple of chunks')\n",
    "parser.add_argument('--pretend'        , action='store_true'  , help = 'Read json files but, not execute the analysis')\n",
    "#parser.add_argument('--nworkers','-n'   , default=8  , help = 'Number of workers')\n",
    "parser.add_argument('--chunksize','-s'   , default=500000  , help = 'Number of events per chunk')\n",
    "parser.add_argument('--nchunks','-c'   , default=None  , help = 'You can choose to run only a number of chunks')\n",
    "parser.add_argument('--outname','-o'   , default='plotsTopEFT', help = 'Name of the output file with histograms')\n",
    "parser.add_argument('--outpath','-p'   , default='histos', help = 'Name of the output directory')\n",
    "parser.add_argument('--treename'   , default='Events', help = 'Name of the tree inside the files')\n",
    "parser.add_argument('--do-errors', action='store_true', help = 'Save the w**2 coefficients')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.jsonFiles is not None:\n",
    "  jsonFiles    = args.jsonFiles\n",
    "  print('jsonFiles {}'.format(args.jsonFiles))\n",
    "else:\n",
    "  with importlib.resources.path(\"topcoffea.json\", \"TTZToLLNuNu_M10.json\") as path:\n",
    "    jsonFiles = str(path)\n",
    "    print('jsonFile was selected for UNL {}'.format(jsonFiles))\n",
    "    \n",
    "if args.prefix is not None:\n",
    "  prefix    = args.prefix\n",
    "else:\n",
    "  prefix = \"root://xcache//\"\n",
    "\n",
    "dotest     = args.test\n",
    "#nworkers   = int(args.nworkers)\n",
    "chunksize  = int(args.chunksize)\n",
    "nchunks    = int(args.nchunks) if not args.nchunks is None else args.nchunks\n",
    "outname    = args.outname\n",
    "outpath    = args.outpath\n",
    "pretend    = args.pretend\n",
    "treename   = args.treename\n",
    "do_errors = args.do_errors\n",
    "\n",
    "if dotest:\n",
    "  nchunks = 2\n",
    "  chunksize = 10000\n",
    "  nworkers = 1\n",
    "  print('Running a fast test with %i workers, %i chunks of %i events'%(nworkers, nchunks, chunksize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e4d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/cms-jovyan/topcoffea/topcoffea/json/TTZToLLNuNu_M10.json']\n",
      ">> TTZToLLNuNu_M10\n",
      "   - isData?      : NO\n",
      "   - year         : 2018\n",
      "   - xsec         : 0.252900\n",
      "   - histAxisName : \n",
      "   - options      : \n",
      "   - tree         : Events\n",
      "   - nEvents      : 14542666\n",
      "   - nGenEvents   : 4876491\n",
      "   - SumWeights   : 19992000.000000\n",
      "   - Prefix       : root://xcache//\n",
      "   - nFiles       : 18\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_1.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_10.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_11.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_12.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_13.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_14.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_15.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_16.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_17.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_18.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_2.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_3.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_4.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_5.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_6.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_7.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_8.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_9.root\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samplesdict = {}\n",
    "allInputFiles = []\n",
    "\n",
    "def LoadJsonToSampleName(jsonFile, prefix):\n",
    "  sampleName = jsonFile if not '/' in jsonFile else jsonFile[jsonFile.rfind('/')+1:]\n",
    "  if sampleName.endswith('.json'): sampleName = sampleName[:-5]\n",
    "  with open(jsonFile) as jf:\n",
    "    samplesdict[sampleName] = json.load(jf)\n",
    "    samplesdict[sampleName]['redirector'] = prefix\n",
    "\n",
    "if  isinstance(jsonFiles, str) and ',' in jsonFiles: jsonFiles = jsonFiles.replace(' ', '').split(',')\n",
    "elif isinstance(jsonFiles, str)                     : jsonFiles = [jsonFiles]\n",
    "\n",
    "for jsonFile in jsonFiles:\n",
    "  if os.path.isdir(jsonFile):\n",
    "    if not jsonFile.endswith('/'): jsonFile+='/'\n",
    "    for f in os.path.listdir(jsonFile):\n",
    "      if f.endswith('.json'): allInputFiles.append(jsonFile+f)\n",
    "  else:\n",
    "    allInputFiles.append(jsonFile)\n",
    "\n",
    "print(allInputFiles)\n",
    "# Read from cfg files\n",
    "for f in allInputFiles:\n",
    "  if not os.path.isfile(f):\n",
    "    print('[WARNING] Input file \"%s% not found!'%f)\n",
    "    continue\n",
    "  # This input file is a json file, not a cfg\n",
    "  if f.endswith('.json'): \n",
    "    LoadJsonToSampleName(f, prefix)\n",
    "  # Open cfg files\n",
    "  else:\n",
    "    with open(f) as fin:\n",
    "      print(' >> Reading json from cfg file...')\n",
    "      lines = fin.readlines()\n",
    "      for l in lines:\n",
    "        if '#' in l: l=l[:l.find('#')]\n",
    "        l = l.replace(' ', '').replace('\\n', '')\n",
    "        if l == '': continue\n",
    "        if ',' in l:\n",
    "          l = l.split(',')\n",
    "          for nl in l:\n",
    "            if not os.path.isfile(l): prefix = nl\n",
    "            else: LoadJsonToSampleName(nl, prefix)\n",
    "        else:\n",
    "          if not os.path.isfile(l): prefix = l\n",
    "          else: LoadJsonToSampleName(l, prefix)\n",
    "\n",
    "flist = {};\n",
    "for sname in samplesdict.keys():\n",
    "  redirector = samplesdict[sname]['redirector']\n",
    "  flist[sname] = [(redirector+f) for f in samplesdict[sname]['files']]\n",
    "  samplesdict[sname]['year'] = int(samplesdict[sname]['year'])\n",
    "  samplesdict[sname]['xsec'] = float(samplesdict[sname]['xsec'])\n",
    "  samplesdict[sname]['nEvents'] = int(samplesdict[sname]['nEvents'])\n",
    "  samplesdict[sname]['nGenEvents'] = int(samplesdict[sname]['nGenEvents'])\n",
    "  samplesdict[sname]['nSumOfWeights'] = float(samplesdict[sname]['nSumOfWeights'])\n",
    "\n",
    "  # Print file info\n",
    "  print('>> '+sname)\n",
    "  print('   - isData?      : %s'   %('YES' if samplesdict[sname]['isData'] else 'NO'))\n",
    "  print('   - year         : %i'   %samplesdict[sname]['year'])\n",
    "  print('   - xsec         : %f'   %samplesdict[sname]['xsec'])\n",
    "  print('   - histAxisName : %s'   %samplesdict[sname]['histAxisName'])\n",
    "  print('   - options      : %s'   %samplesdict[sname]['options'])\n",
    "  print('   - tree         : %s'   %samplesdict[sname]['treeName'])\n",
    "  print('   - nEvents      : %i'   %samplesdict[sname]['nEvents'])\n",
    "  print('   - nGenEvents   : %i'   %samplesdict[sname]['nGenEvents'])\n",
    "  print('   - SumWeights   : %f'   %samplesdict[sname]['nSumOfWeights'])\n",
    "  print('   - Prefix       : %s'   %samplesdict[sname]['redirector'])\n",
    "  print('   - nFiles       : %i'   %len(samplesdict[sname]['files']))\n",
    "  for fname in samplesdict[sname]['files']: print('     %s'%fname)\n",
    "\n",
    "if pretend: \n",
    "  print('pretending...')\n",
    "  exit() \n",
    "\n",
    "# Check that all datasets have the same list of WCs\n",
    "for i,k in enumerate(samplesdict.keys()):\n",
    "  if i == 0:\n",
    "    wc_lst = samplesdict[k]['WCnames']\n",
    "  if wc_lst != samplesdict[k]['WCnames']:\n",
    "    raise Exception(\"Not all of the datasets have the same list of WCs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0c41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#                                       ] | 2% Completed |  0.1s4s\r"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'topcoffea.analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-15f57983dbb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run the processor and get the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m output = processor.run_uproot_job(flist,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                   \u001b[0mtreename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtreename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                   \u001b[0mprocessor_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py\u001b[0m in \u001b[0;36mrun_uproot_job\u001b[0;34m(fileset, treename, processor_instance, executor, executor_args, pre_executor, pre_args, chunksize, maxchunks, metadata_cache)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     }\n\u001b[1;32m   1234\u001b[0m     \u001b[0mexe_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m     \u001b[0mwrapped_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexe_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[0mprocessor_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py\u001b[0m in \u001b[0;36mdask_executor\u001b[0;34m(items, function, accumulator, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;31m# FIXME: fancy widget doesn't appear, have to live with boring pbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_decompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cancelled\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# no @wraps due to pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py\u001b[0m in \u001b[0;36m_work_function\u001b[0;34m()\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorABC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mprocessor_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlz4f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[0mretry_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'topcoffea.analysis'"
     ]
    }
   ],
   "source": [
    "processor_instance = topcoffea.analysis.topEFT.topeft.AnalysisProcessor(samplesdict,wc_lst,do_errors)\n",
    "\n",
    "client = Client(\"tls://localhost:8786\")\n",
    "client.register_worker_plugin(dependency_installer)\n",
    "\n",
    "executor_args = {\n",
    "                 'schema': NanoAODSchema,\n",
    "                 'client': client\n",
    "}\n",
    "\n",
    "# Run the processor and get the output                                                                                                                                                                     \n",
    "tstart = time.time()\n",
    "output = processor.run_uproot_job(flist,\n",
    "                                  treename=treename,\n",
    "                                  processor_instance=processor_instance,\n",
    "                                  executor=processor.dask_executor,\n",
    "                                  executor_args=executor_args,\n",
    "                                  chunksize=chunksize,\n",
    "                                  maxchunks=nchunks\n",
    "                                 )\n",
    "dt = time.time() - tstart\n",
    "\n",
    "nbins = sum(sum(arr.size for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "nfilled = sum(sum(np.sum(arr > 0) for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "print(\"Filled %.0f bins, nonzero bins: %1.1f %%\" % (nbins, 100*nfilled/nbins,))\n",
    "print(\"Processing time: %1.2f s with %i workers (%.2f s cpu overall)\" % (dt, nworkers, dt*nworkers, ))\n",
    "\n",
    "# This is taken from the DM photon analysis...                                                                                                                                                             \n",
    "# Pickle is not very fast or memory efficient, will be replaced by something better soon                                                                                                                   \n",
    "#    with lz4f.open(\"pods/\"+options.year+\"/\"+dataset+\".pkl.gz\", mode=\"xb\", compression_level=5) as fout:                                                                                                   \n",
    "if not outpath.endswith('/'): outpath += '/'\n",
    "if not os.path.isdir(outpath): os.system(\"mkdir -p %s\"%outpath)\n",
    "print('Saving output in %s...'%(outpath + outname + \".pkl.gz\"))\n",
    "with gzip.open(outpath + outname + \".pkl.gz\", \"wb\") as fout:\n",
    "  cloudpickle.dump(output, fout)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d257d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
